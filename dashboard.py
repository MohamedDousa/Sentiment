# -*- coding: utf-8 -*-
"""dashboard.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h5jKEAgeXA9i8KfegWpUxIOMPNMrkQjT
"""

# dashboard.py - Streamlit frontend
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import requests
import json
import io
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
import traceback

# Set page configuration
st.set_page_config(
    page_title="Feedback Analysis Dashboard",
    page_icon="📊",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Define API endpoint
API_URL = "http://localhost:8000"  # Update with your FastAPI server URL

# Function to check API connection
def check_api_connection():
    try:
        response = requests.get(f"{API_URL}/")
        return response.status_code == 200
    except Exception as e:
        st.sidebar.error(f"API connection error: {str(e)}")
        return False

# Function to upload file to API
def upload_file(file):
    try:
        files = {"file": file}
        response = requests.post(f"{API_URL}/upload", files=files)
        if response.status_code != 200:
            st.error(f"API returned status code {response.status_code}: {response.text}")
            return None
            
        response_data = response.json()
        # Assuming your API response contains comments_processed and departments_processed
        return {
            "comments_processed": response_data.get("comments_processed", 0),
            "departments_processed": response_data.get("departments_processed", 0)
            # Other keys from response_data if needed
        }
    except Exception as e:
        st.error(f"Error uploading file: {str(e)}")
        st.error(f"Traceback: {traceback.format_exc()}")
        return None

# Function to get all risk scores
def get_all_risks():
    try:
        response = requests.get(f"{API_URL}/risk/all")

        # Debug information
        st.sidebar.write(f"Debug - Risk API Response Status: {response.status_code}")
        
        # Check if the response status is OK
        if response.status_code == 200:
            data = response.json()
            
            # Debug the actual response content
            st.sidebar.write(f"Debug - Risk API Response Content (sample): {str(data)[:200]}...")

            # Check the data type
            if isinstance(data, list) and len(data) > 0:
                return data
            else:
                st.sidebar.warning(f"Debug - Unexpected risk data format: {type(data)}")
                # Attempt to handle various formats
                if isinstance(data, dict) and "departments" in data:
                    return data.get("departments", [])
                elif isinstance(data, dict):
                    # Try to convert dict to list of dicts
                    return [{"department": k, "risk_score": v, "high_risk": False} for k, v in data.items()]
                else:
                    return []
        else:
            st.sidebar.error(f"Debug - Risk API error: {response.status_code}")
            st.sidebar.error(f"Response content: {response.text}")
            return []
    except Exception as e:
        st.sidebar.error(f"Debug - Error fetching risks: {str(e)}")
        st.sidebar.error(f"Traceback: {traceback.format_exc()}")
        return []

# Function to get department list
def get_departments():
    try:
        response = requests.get(f"{API_URL}/departments")
        if response.status_code != 200:
            st.sidebar.error(f"Departments API error: {response.status_code}: {response.text}")
            return []
        return response.json().get("departments", [])
    except Exception as e:
        st.sidebar.error(f"Error fetching departments: {str(e)}")
        return []

# Function to get theme summary
def get_themes_summary():
    try:
        response = requests.get(f"{API_URL}/themes/summary")
        if response.status_code != 200:
            st.sidebar.error(f"Themes API error: {response.status_code}: {response.text}")
            return {}
        return response.json().get("themes", {})
    except Exception as e:
        st.sidebar.error(f"Error fetching themes: {str(e)}")
        return {}

# Function to get data summary
def get_data_summary():
    try:
        response = requests.get(f"{API_URL}/data/summary")
        if response.status_code != 200:
            st.sidebar.error(f"Data summary API error: {response.status_code}: {response.text}")
            return None
        return response.json()
    except Exception as e:
        st.sidebar.error(f"Error fetching data summary: {str(e)}")
        return None

# Function to get sample comments
def get_sample_comments(department=None, theme=None, limit=5):
    try:
        params = {}
        if department:
            params["department"] = department
        if theme:
            params["theme"] = theme
        if limit:
            params["limit"] = limit

        response = requests.get(f"{API_URL}/comments/sample", params=params)
        if response.status_code != 200:
            st.error(f"Comments API error: {response.status_code}: {response.text}")
            return []
        return response.json().get("samples", [])
    except Exception as e:
        st.error(f"Error fetching comments: {str(e)}")
        return []

# Function to get specific department risk
def get_department_risk(department):
    try:
        response = requests.get(f"{API_URL}/risk/{department}")
        if response.status_code != 200:
            st.error(f"Department risk API error: {response.status_code}: {response.text}")
            return None
        return response.json()
    except Exception as e:
        st.error(f"Error fetching department risk: {str(e)}")
        return None

# Sidebar for file upload and navigation
st.sidebar.title("Staff Feedback Analysis")

# Check API connection
if not check_api_connection():
    st.sidebar.error("❌ Cannot connect to API server. Please make sure it's running.")
    st.error("Cannot connect to the API server. Please start the server with `uvicorn api:app --reload`")
    st.stop()
else:
    st.sidebar.success("✅ Connected to API server")

# File upload
st.sidebar.header("Data Upload")
uploaded_file = st.sidebar.file_uploader("Upload Staff Feedback Data", type=["csv", "xlsx", "xls"])

if uploaded_file:
    if st.sidebar.button("Process Data"):
        with st.spinner("Processing data... This may take a minute."):
            result = upload_file(uploaded_file)
            if result:
                st.sidebar.success(f"✅ Processed {result['comments_processed']} comments across {result['departments_processed']} departments")
            else:
                st.sidebar.error("❌ Error processing file")

# Navigation
st.sidebar.header("Navigation")
page = st.sidebar.radio(
    "Select Page",
    ["Dashboard", "Department Details", "Comment Explorer", "About"]
)

# Get data from API
data_summary = get_data_summary()
all_risks = get_all_risks()
departments = get_departments()
themes_summary = get_themes_summary()

# Main content based on selected page
if page == "Dashboard":
    st.title("Staff Feedback Analysis Dashboard")

    if not data_summary:
        st.info("No data loaded. Please upload a file using the sidebar.")
        st.stop()

    # Dashboard metrics row
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("Total Comments", data_summary.get("total_comments", 0))  # Using .get() with default value

    with col2:
        st.metric("Departments", data_summary.get("total_departments", 0))

    with col3:
        total_depts = data_summary.get("total_departments", 1)  # Default to 1 to avoid division by zero
        high_risk_depts = data_summary.get("high_risk_departments", 0)
        high_risk_pct = round(high_risk_depts / total_depts * 100) if total_depts > 0 else 0
        st.metric("High Risk Depts", f"{high_risk_depts} ({high_risk_pct}%)")

    with col4:
        total_comments = data_summary.get("total_comments", 1)  # Default to 1 to avoid division by zero
        sentiment_dist = data_summary.get("sentiment_distribution", {})
        negative_comments = sentiment_dist.get("negative", 0)
        negative_pct = round(negative_comments / total_comments * 100) if total_comments > 0 else 0
        st.metric("Negative Comments", f"{negative_comments} ({negative_pct}%)")

        st.markdown("---")

    # Risk scores and themes visualization
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Department Risk Scores")

        if all_risks:
            # First, debug the structure of all_risks to understand what we're dealing with
            st.write("DEBUG: Examining the structure of risk data")
            st.write(f"Type of all_risks: {type(all_risks)}")
            st.write(f"First few items: {str(all_risks)[:200]}..." if all_risks else "No items")

            # Prepare data for risk score visualization based on the type of all_risks
            risk_data = []

            try:
                # Case 1: all_risks is a list of dictionaries
                if isinstance(all_risks, list) and all_risks and isinstance(all_risks[0], dict):
                    for dept in all_risks:
                        risk_data.append({
                            "department": dept.get("department", "Unknown"),
                            "risk_score": dept.get("risk_score", 0),
                            "high_risk": "Yes" if dept.get("high_risk", False) else "No"
                        })

                # Case 2: all_risks is a list of strings (department names)
                elif isinstance(all_risks, list) and all_risks and isinstance(all_risks[0], str):
                    for dept_name in all_risks:
                        # Here we just have department names without risk scores
                        risk_data.append({
                            "department": dept_name,
                            "risk_score": 0,  # Default value
                            "high_risk": "No"  # Default value
                        })

                # Case 3: all_risks is a DataFrame
                elif hasattr(all_risks, 'iterrows'):
                    for _, row in all_risks.iterrows():
                        risk_data.append({
                            "department": row.get("department", "Unknown") if hasattr(row, 'get') else str(row.department),
                            "risk_score": float(row.get("risk_score", 0)) if hasattr(row, 'get') else float(row.risk_score),
                            "high_risk": "Yes" if (hasattr(row, 'get') and row.get("high_risk", False)) or
                                           (hasattr(row, 'high_risk') and row.high_risk) else "No"
                        })

                # Case 4: all_risks has some other structure we didn't anticipate
                else:
                    st.error(f"Unexpected data structure for risk scores: {type(all_risks)}")
                    st.json(all_risks)  # Display the actual data for debugging
                    st.stop()

                if risk_data:
                    risk_df = pd.DataFrame(risk_data)
                    st.write("DEBUG: Processed risk data")
                    st.write(risk_df.head())

                    # Create Plotly bar chart
                    try:
                        fig = px.bar(
                            risk_df.sort_values("risk_score", ascending=False).head(10),
                            x="department",
                            y="risk_score",
                            color="high_risk",
                            color_discrete_map={"Yes": "red", "No": "blue"},
                            title="Top 10 Departments by Risk Score",
                            labels={"department": "Department", "risk_score": "Risk Score (1-5)", "high_risk": "High Risk"}
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    except Exception as e:
                        st.error(f"Error creating risk visualization: {str(e)}")
                        st.error(f"Traceback: {traceback.format_exc()}")
                else:
                    st.info("No valid risk data available to display")

            except Exception as e:
                st.error(f"Error processing risk data: {str(e)}")
                st.error(f"Traceback: {traceback.format_exc()}")
                st.write("Please check the data structure returned from the API.")
        else:
            st.info("No risk data available")

    with col2:
        st.subheader("Top Themes Across All Departments")

        if themes_summary:
            # Create theme data for visualization
            theme_data = []
            for theme, count in themes_summary.items():
                theme_data.append({
                    "theme": theme,
                    "count": count
                })

            if theme_data:
                theme_df = pd.DataFrame(theme_data)
                st.write("DEBUG: Theme data")
                st.write(theme_df.head())

                # Create Plotly bar chart
                try:
                    fig = px.bar(
                        theme_df.sort_values("count", ascending=False),
                        x="theme",
                        y="count",
                        title="Theme Frequency Across All Departments",
                        labels={"theme": "Theme", "count": "Occurrence Count"},
                        color="count",
                        color_continuous_scale="Viridis"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"Error creating theme visualization: {str(e)}")
                    st.error(f"Traceback: {traceback.format_exc()}")
            else:
                st.info("No valid theme data available")
        else:
            st.info("No theme data available")

    # Sentiment distribution
    st.subheader("Sentiment Distribution")

    if data_summary and "sentiment_distribution" in data_summary:
        # Create sentiment data
        sentiment_data = []
        sentiment_dist = data_summary.get("sentiment_distribution", {})
        
        st.write("DEBUG: Sentiment distribution data")
        st.write(sentiment_dist)

        for sentiment, count in sentiment_dist.items():
            sentiment_data.append({
                "sentiment": sentiment.capitalize(),
                "count": count
            })

        if sentiment_data:
            sentiment_df = pd.DataFrame(sentiment_data)

            # Create Plotly pie chart
            try:
                fig = px.pie(
                    sentiment_df,
                    values="count",
                    names="sentiment",
                    title="Sentiment Distribution",
                    color="sentiment",
                    color_discrete_map={
                        "Positive": "green",
                        "Neutral": "gray",
                        "Negative": "red"
                    }
                )
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"Error creating sentiment visualization: {str(e)}")
                st.error(f"Traceback: {traceback.format_exc()}")
        else:
            st.info("No valid sentiment data available")
    else:
        st.info("No sentiment data available")

    # High risk departments table
    st.subheader("High Risk Departments")

    if all_risks:
        try:
            high_risk_depts = [dept for dept in all_risks if isinstance(dept, dict) and dept.get("high_risk", False)]

            if high_risk_depts:
                # Create table data
                table_data = []
                for dept in high_risk_depts:
                    # Get top themes
                    top_themes = []
                    dept_themes = dept.get("top_themes", [])
                    if isinstance(dept_themes, list):
                        for theme in dept_themes:
                            if isinstance(theme, dict):
                                feature = theme.get("feature", "Unknown")
                                contribution = theme.get("contribution_pct", 0)
                                top_themes.append(f"{feature}: {contribution}%")

                    table_data.append({
                        "Department": dept.get("department", "Unknown"),
                        "Risk Score": f"{dept.get('risk_score', 0):.1f}",
                        "Top Contributing Factors": ", ".join(top_themes[:3]) if top_themes else "N/A"
                    })

                st.table(pd.DataFrame(table_data))
            else:
                st.success("No high-risk departments identified")
        except Exception as e:
            st.error(f"Error displaying high risk departments: {str(e)}")
            st.error(f"Traceback: {traceback.format_exc()}")
    else:
        st.info("No risk data available")

elif page == "Department Details":
    st.title("Department Details")

    if not departments:
        st.info("No departments available. Please upload data first.")
        st.stop()

    # Department selector
    selected_dept = st.selectbox("Select Department", departments)

    if selected_dept:
        # Get department risk data
        dept_risk = get_department_risk(selected_dept)

        if dept_risk:
            # Department header with risk score
            col1, col2 = st.columns([3, 1])

            with col1:
                st.header(selected_dept)

            with col2:
                risk_color = "red" if dept_risk.get("high_risk", False) else "blue"
                risk_score = dept_risk.get("risk_score", 0)
                st.markdown(f"<h2 style='color:{risk_color};'>Risk: {risk_score:.1f}/5.0</h2>", unsafe_allow_html=True)

            # Risk factors
            st.subheader("Risk Factors")

            top_themes = dept_risk.get("top_themes", [])
            if top_themes and isinstance(top_themes, list) and len(top_themes) > 0:
                # Create gauge charts for top themes
                col1, col2, col3 = st.columns(3)
                cols = [col1, col2, col3]

                for i, theme in enumerate(top_themes[:3]):
                    if not isinstance(theme, dict):
                        continue

                    with cols[i % 3]:
                        try:
                            feature = theme.get("feature", "Unknown").replace("_", " ").title()
                            contribution = theme.get("contribution_pct", 0)

                            # Create gauge chart
                            fig = go.Figure(go.Indicator(
                                mode="gauge+number",
                                value=contribution,
                                domain={"x": [0, 1], "y": [0, 1]},
                                title={"text": feature},
                                gauge={
                                    "axis": {"range": [0, 100]},
                                    "bar": {"color": "darkblue"},
                                    "steps": [
                                        {"range": [0, 33], "color": "lightgreen"},
                                        {"range": [33, 66], "color": "lightyellow"},
                                        {"range": [66, 100], "color": "salmon"}
                                    ]
                                }
                            ))

                            fig.update_layout(height=250)
                            st.plotly_chart(fig, use_container_width=True)
                        except Exception as e:
                            st.error(f"Error displaying theme gauge: {str(e)}")
                            st.error(f"Traceback: {traceback.format_exc()}")
            else:
                st.info("No risk factor data available for this department")


            # Theme analysis for this department
            st.subheader("Sample Comments")

            comments = get_sample_comments(department=selected_dept, limit=5)

            if comments and isinstance(comments, list):
                for i, comment in enumerate(comments):
                    if not isinstance(comment, dict):
                        continue

                    # Check if sentiment_score exists, use default if not
                    score = comment.get("sentiment_score", 0.5)
                    
                    # Convert score to sentiment category
                    sentiment_category = "NEUTRAL"
                    if score > 0.6:
                        sentiment_category = "POSITIVE"
                    elif score < 0.4:
                        sentiment_category = "NEGATIVE"

                    sentiment_color = {
                        "POSITIVE": "green",
                        "NEGATIVE": "red",
                        "NEUTRAL": "gray"
                    }.get(sentiment_category, "gray")

                    comment_text = comment.get("free_text_comments", "")

                    st.markdown(f"""
                    <div style="padding: 10px; border-left: 5px solid {sentiment_color}; background-color: rgba(0,0,0,0.1); margin-bottom: 10px; border-radius: 5px;">
                        <p style="color: {sentiment_color}; margin: 0 0 5px 0; font-weight: bold; text-shadow: 0px 0px 1px rgba(150,150,150,0.3);">Sentiment: {sentiment_category}</p>
                        <p style="margin: 0; color: inherit; font-size: 14px;">{comment_text}</p>
                    </div>
                    """, unsafe_allow_html=True)
            else:
                st.info("No sample comments available for this department")
        else:
            st.error(f"Could not retrieve data for department: {selected_dept}")

elif page == "Comment Explorer":
    st.title("Comment Explorer")

    if not data_summary:
        st.info("No data loaded. Please upload a file first.")
        st.stop()

    # Filters
    col1, col2, col3 = st.columns(3)

    departments_list = ["All"]
    if departments and isinstance(departments, list):
        departments_list.extend(departments)

    themes_list = ["All"]
    if themes_summary and isinstance(themes_summary, dict):
        themes_list.extend(list(themes_summary.keys()))

    with col1:
        filter_dept = st.selectbox("Department", departments_list)

    with col2:
        filter_theme = st.selectbox("Theme", themes_list)

    with col3:
        filter_sentiment = st.selectbox("Sentiment", ["All", "Positive", "Neutral", "Negative"])

    # Convert filters to API parameters
    api_dept = None if filter_dept == "All" else filter_dept
    api_theme = None if filter_theme == "All" else filter_theme

    # Get comments based on filters
    try:
        comments = get_sample_comments(department=api_dept, theme=api_theme, limit=50)
    except Exception as e:
        st.error(f"Error fetching comments: {str(e)}")
        st.error(f"Traceback: {traceback.format_exc()}")
        comments = []

    # Filter by sentiment (client-side)
    if comments and filter_sentiment != "All":
        try:
            filtered_comments = []
            for c in comments:
                # Check if sentiment_score exists, use default if not
                score = c.get("sentiment_score", 0.5)
                sentiment_category = "NEUTRAL"
                if score > 0.6:
                    sentiment_category = "POSITIVE"
                elif score < 0.4:
                    sentiment_category = "NEGATIVE"
                    
                if sentiment_category == filter_sentiment.upper():
                    filtered_comments.append(c)
            comments = filtered_comments
        except Exception as e:
            st.error(f"Error filtering comments by sentiment: {str(e)}")
            st.error(f"Traceback: {traceback.format_exc()}")

    # Display comments
    st.subheader(f"Comments ({len(comments) if comments else 0} matching)")

    if comments and isinstance(comments, list):
        for comment in comments:
            if not isinstance(comment, dict):
                continue

            dept = comment.get("department", "Unknown")
            text = comment.get("free_text_comments", "")
            
            # Check if sentiment_score exists, use default if not
            score = comment.get("sentiment_score", 0.5)
            
            # Convert score to sentiment category
            sentiment_category = "NEUTRAL"
            if score > 0.6:
                sentiment_category = "POSITIVE"
            elif score < 0.4:
                sentiment_category = "NEGATIVE"

            sentiment_color = {
                "POSITIVE": "green",
                "NEGATIVE": "red",
                "NEUTRAL": "gray"
            }.get(sentiment_category, "gray")

            st.markdown(f"""
            <div style="padding: 15px; border-left: 5px solid {sentiment_color}; background-color: rgba(0,0,0,0.1); margin-bottom: 15px; border-radius: 5px;">
                <p style="color: lightblue; margin: 0; font-weight: bold;">{dept}</p>
                <p style="color: {sentiment_color}; margin: 5px 0; font-size: 0.9em; font-weight: bold; text-shadow: 0px 0px 1px rgba(150,150,150,0.3);">Sentiment: {sentiment_category.capitalize()} ({score:.2f})</p>
                <p style="margin: 10px 0 0 0; color: inherit; font-size: 14px;">{text}</p>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.info("No comments match the selected filters")

elif page == "About":
    st.title("About This Dashboard")

    st.markdown("""
    ## Staff Feedback Analysis Tool

    This tool analyzes anonymous staff feedback to identify themes and sentiment in employee comments.

    ### How It Works

    1. **Data Loading**: Upload CSV or Excel files with department and comment data.
    2. **NLP Processing**:
       - Sentiment analysis using DistilBERT transformer model
       - Theme extraction with rule-based pattern matching
    3. **Risk Scoring**:
       - Derived from sentiment scores (more negative sentiment = higher risk)
       - Identification of dominant themes by department
    4. **Dashboard Visualization**:
       - Department risk scores
       - Theme frequency analysis
       - Comment samples with sentiment

    ### Technologies Used

    * **Data Processing**: Pandas
    * **NLP**: Hugging Face Transformers, spaCy
    * **Backend**: FastAPI
    * **Frontend**: Streamlit

    ### Interpreting Results

    * **Sentiment Scores**: 0-1 scale (higher = more positive sentiment)
    * **Risk Scores**: 1-5 scale (higher = higher risk, derived from inverted sentiment)
    * **Themes**: Key topics mentioned in comments (e.g., workload, staffing)

    This is a simplified version that focuses on NLP analysis without prediction modeling.
    """)

# Display last updated timestamp
if data_summary and "last_updated" in data_summary:
    st.sidebar.markdown(f"**Last Updated**: {data_summary['last_updated']}")

# Run with: streamlit run dashboard.py